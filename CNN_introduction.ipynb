{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "This is a simple image classifier using the CIFAR-10 dataset."
      ],
      "metadata": {
        "id": "ovzCiCdxZBkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1\n",
        "Installing PyTorch and TorchVision for building the machine learning model and Matplotlib for ploting the results."
      ],
      "metadata": {
        "id": "VM0BWEe8YzxM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPWHHGmVYUf9"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2\n",
        "Importing the necessary libraries"
      ],
      "metadata": {
        "id": "rehG5QjLZWy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA is available! Device: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Check runtime settings.\")"
      ],
      "metadata": {
        "id": "4Mf_Ti2oZb7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3\n",
        "Loading the CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "fpj0WKZJZd_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for the training and test sets\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), # converts a PIL image to a tensor and transforms the values {0,...255} --> [0, 1]\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # first tuple -> means, second tuple -> std's. output=(input-mean)/std\n",
        "# The image has three color channels (RGB) and therefore the tuples have three elements, one for each color\n",
        "\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Define class names\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Assuming 'net' is your model and 'inputs', 'labels' are your data\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "KHfyHK4mZyAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4\n",
        "Exploring the Data - visualize a few images from the dataset to understand what you are working with:"
      ],
      "metadata": {
        "id": "_G3EQSkZyrYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize - [-1,1] --> [0,1]\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# Print labels\n",
        "print(' '.join(f'{classes[labels[j]]}' for j in range(4)))"
      ],
      "metadata": {
        "id": "x8lizF8Zyx3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5\n",
        "Build the CNN Model and define the architecture."
      ],
      "metadata": {
        "id": "3LVSig4azvEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)       # num of input channels (3-RGB), num of output channels (6), kernel size (5x5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)        # kernel size (2x2), stride (step size, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)      # num of input channels (6-from conv1), num of output channels (16), kernel size (5x5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 16 * 5 * 5 input features (flattened output of the last convolutional layer), 120 output features\n",
        "        self.fc2 = nn.Linear(120, 84)         # -||-\n",
        "        self.fc3 = nn.Linear(84, 10)          # -||-\n",
        "        # Note - num of channels is the number of so-called 'filters'\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5) # flattening of the tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "        # Data flow:      x      ->   conv1    ->  relu  ->   pool    ->   conv2    ->  relu  ->   pool   -> view  ->  fc1  -> relu  -> fc2  -> relu  -> fc3\n",
        "        # Shape of x: N×3×32×32  ->  N×6×28×28 ->  const -> N×6×14×14 -> N×16×10×10 ->  const -> N×16×5×5 -> N×400 -> N×120 -> const -> N×84 -> const -> N×10\n",
        "\n",
        "net = Net()\n",
        "\n",
        "# Assuming 'net' is your model and 'inputs', 'labels' are your data\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move model to the device (GPU or CPU)\n",
        "net.to(device)\n",
        "\n",
        "# Example of moving tensors to GPU\n",
        "# inputs, labels = inputs.to(device), labels.to(device)"
      ],
      "metadata": {
        "id": "1_2BGNiy0AVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6\n",
        "Define a Loss Function and Optimizer:"
      ],
      "metadata": {
        "id": "KTBBFiQ67eq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "7e1WFw6Q7dkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7\n",
        "Train the Model"
      ],
      "metadata": {
        "id": "Fnwib4Y8-tvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):  # example with 5 epochs\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "5TahLt6a-0I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "Evaluate the model's performance on the test data:"
      ],
      "metadata": {
        "id": "gaMzu8p-AAZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# We do not need to track gradients for evaluation\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = net(images)\n",
        "\n",
        "        # Get the predicted class with the highest score\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Print accuracy\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n"
      ],
      "metadata": {
        "id": "Vl_CDtP_AJnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a nice visualization for the predictions on a batch of data:"
      ],
      "metadata": {
        "id": "MXnFeeJwGses"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Ensure the model is on the GPU\n",
        "net.to(device)\n",
        "\n",
        "dataiter = iter(testloader)"
      ],
      "metadata": {
        "id": "gGRgJPYRFuoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(dataiter)\n",
        "\n",
        "# Move the inputs and labels to the GPU\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "# Print images\n",
        "imshow(torchvision.utils.make_grid(images.cpu()))  # Move images back to CPU for visualization\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]}' for j in range(4)))\n",
        "\n",
        "# Get predictions from the model\n",
        "outputs = net(images)\n",
        "\n",
        "# Get the predicted class with the highest score\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]}' for j in range(4)))"
      ],
      "metadata": {
        "id": "ZPzr2oRsKK0T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}